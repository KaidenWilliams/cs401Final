{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb66cc0-4ce6-4855-8773-9c0bb222b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc8904b-8137-4412-a844-eace6defc1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "--extra-index-url https://download.pytorch.org/whl/cu118\n",
    "torch==2.5.1+cu118  # Explicit CUDA suffix\n",
    "torchaudio==2.5.1+cu118\n",
    "librosa>=0.9.0\n",
    "numpy>=1.20.0\n",
    "soundfile>=0.10.3\n",
    "boto3>=1.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f18e731f-bbbb-4eae-9eb5-94999c6b16ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch==2.5.1+cu118 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.5.1+cu118)\n",
      "Requirement already satisfied: torchaudio==2.5.1+cu118 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (2.5.1+cu118)\n",
      "Requirement already satisfied: librosa>=0.9.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (1.26.4)\n",
      "Requirement already satisfied: soundfile>=0.10.3 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (0.13.1)\n",
      "Requirement already satisfied: boto3>=1.24.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (1.37.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (11.8.86)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1+cu118->-r requirements.txt (line 3)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.5.1+cu118->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.12/site-packages (from librosa>=0.9.0->-r requirements.txt (line 5)) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.12/site-packages (from librosa>=0.9.0->-r requirements.txt (line 5)) (0.61.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from librosa>=0.9.0->-r requirements.txt (line 5)) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from librosa>=0.9.0->-r requirements.txt (line 5)) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/conda/lib/python3.12/site-packages (from librosa>=0.9.0->-r requirements.txt (line 5)) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.12/site-packages (from librosa>=0.9.0->-r requirements.txt (line 5)) (5.2.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.12/site-packages (from librosa>=0.9.0->-r requirements.txt (line 5)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.12/site-packages (from librosa>=0.9.0->-r requirements.txt (line 5)) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.12/site-packages (from librosa>=0.9.0->-r requirements.txt (line 5)) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.12/site-packages (from librosa>=0.9.0->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.12/site-packages (from soundfile>=0.10.3->-r requirements.txt (line 7)) (1.17.1)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.1 in /opt/conda/lib/python3.12/site-packages (from boto3>=1.24.0->-r requirements.txt (line 8)) (1.37.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3>=1.24.0->-r requirements.txt (line 8)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/conda/lib/python3.12/site-packages (from boto3>=1.24.0->-r requirements.txt (line 8)) (0.11.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from botocore<1.38.0,>=1.37.1->boto3>=1.24.0->-r requirements.txt (line 8)) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.12/site-packages (from botocore<1.38.0,>=1.37.1->boto3>=1.24.0->-r requirements.txt (line 8)) (2.3.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.10.3->-r requirements.txt (line 7)) (2.22)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from lazy_loader>=0.1->librosa>=0.9.0->-r requirements.txt (line 5)) (24.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/conda/lib/python3.12/site-packages (from numba>=0.51.0->librosa>=0.9.0->-r requirements.txt (line 5)) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from pooch>=1.1->librosa>=0.9.0->-r requirements.txt (line 5)) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.12/site-packages (from pooch>=1.1->librosa>=0.9.0->-r requirements.txt (line 5)) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn>=1.1.0->librosa>=0.9.0->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch==2.5.1+cu118->-r requirements.txt (line 3)) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.1->boto3>=1.24.0->-r requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.9.0->-r requirements.txt (line 5)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.9.0->-r requirements.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.9.0->-r requirements.txt (line 5)) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d5dd69-7897-4235-8a37-bccc6ed1aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CODE (That maybe has a memory leak?)\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "import gc  # For garbage collection\n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "input_bucket = 'cs401finalpipelineinput'\n",
    "output_bucket = 'cs401finalpipelineprocessingdata'\n",
    "output_prefix = 'data'\n",
    "\n",
    "TEST_COUNT_LIMIT = 7\n",
    "\n",
    "# Load VAD model\n",
    "torch.set_num_threads(1)\n",
    "model, (get_speech_timestamps, _, read_audio, _, _) = torch.hub.load(\n",
    "    repo_or_dir=\"snakers4/silero-vad\", model=\"silero_vad\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "import psutil\n",
    "import os\n",
    "def memory_usage_mb():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_bytes = process.memory_info().rss  # Resident Set Size\n",
    "    return f\"{mem_bytes / (1024 * 1024)} mb\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def list_s3_files(bucket, prefix):\n",
    "    \"\"\"List files in an S3 bucket with given prefix\"\"\"\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n",
    "    \n",
    "    file_list = []\n",
    "    for page in pages:\n",
    "        if \"Contents\" in page:\n",
    "            for obj in page[\"Contents\"]:\n",
    "                file_list.append(obj[\"Key\"])\n",
    "    \n",
    "    return file_list\n",
    "\n",
    "def compute_melspec(audio, sr, n_mels, fmin, fmax):\n",
    "    \"\"\"Compute a mel-spectrogram.\"\"\"\n",
    "    melspec = librosa.feature.melspectrogram(\n",
    "        y=audio,\n",
    "        sr=sr,\n",
    "        n_mels=n_mels,\n",
    "        fmin=fmin,\n",
    "        fmax=fmax,\n",
    "    )\n",
    "\n",
    "    # Convert to log scale (dB)\n",
    "    melspec = librosa.power_to_db(melspec)\n",
    "    return melspec\n",
    "\n",
    "def mono_to_color(X, eps=1e-6, mean=None, std=None):\n",
    "    \"\"\"Convert mono audio to color image format\"\"\"\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    X = (X - mean) / (std + eps)\n",
    "\n",
    "    # Normalize to [0, 255]\n",
    "    _min, _max = X.min(), X.max()\n",
    "    if (_max - _min) > eps:\n",
    "        V = np.clip(X, _min, _max)\n",
    "        V = 255 * (V - _min) / (_max - _min)\n",
    "    else:\n",
    "        V = np.zeros_like(X)\n",
    "\n",
    "    # Convert to uint8\n",
    "    V = V.astype(np.uint8)\n",
    "\n",
    "    # Create RGB channels (stack the same array 3 times)\n",
    "    return np.stack([V, V, V], axis=2)\n",
    "\n",
    "def crop_or_pad(audio, length):\n",
    "    \"\"\"Crop or pad an audio sample to a fixed length.\"\"\"\n",
    "    if len(audio) < length:\n",
    "        # Pad with zeros\n",
    "        audio = np.pad(audio, (0, length - len(audio)))\n",
    "    else:\n",
    "        # Crop to length\n",
    "        audio = audio[:length]\n",
    "    return audio\n",
    "\n",
    "def process_single_file(s3_key, max_size_mb=1.2):\n",
    "    print(f\"Memory at very start: {memory_usage_mb()}\")\n",
    "    \n",
    "    try:\n",
    "        # Extract class from directory structure\n",
    "        path_parts = s3_key.split('/')\n",
    "        parent_dir = path_parts[-2]  # Class name\n",
    "        base_filename = path_parts[-1]  # Filename\n",
    "        base_name = base_filename.split('.')[0] if '.' in base_filename else base_filename\n",
    "\n",
    "        print(f\"Memory Before Downloading Audio File: {memory_usage_mb()}\")\n",
    "        \n",
    "        # Download audio file to memory using context manager\n",
    "        with BytesIO() as audio_buffer:\n",
    "            s3_client.download_fileobj(input_bucket, s3_key, audio_buffer)\n",
    "            audio_buffer.seek(0)\n",
    "\n",
    "            print(f\"Memory After Downloading Audio File: {memory_usage_mb()}\")\n",
    "            \n",
    "            # Check file size\n",
    "            file_size_mb = len(audio_buffer.getvalue()) / (1024 * 1024)\n",
    "            if file_size_mb > max_size_mb:\n",
    "                print(f\"Skipping {base_filename}: {file_size_mb:.1f}MB exceeds {max_size_mb}MB limit\")\n",
    "                return\n",
    "            \n",
    "            # Use BytesIO for VAD model\n",
    "            print(f\"Memory Before audio_buffer and wav: {memory_usage_mb()}\")\n",
    "            \n",
    "            audio_buffer.seek(0)\n",
    "            wav = read_audio(audio_buffer)\n",
    "\n",
    "            print(f\"Memory After audio_buffer and wav: {memory_usage_mb()}\")\n",
    "            \n",
    "            # Get speech timestamps\n",
    "            print(f\"Memory Before speech_timestamps: {memory_usage_mb()}\")\n",
    "            \n",
    "            speech_timestamps = get_speech_timestamps(\n",
    "                wav, model, return_seconds=True, threshold=0.4\n",
    "            )\n",
    "\n",
    "            print(f\"Memory After speech_timestamps: {memory_usage_mb()}\")\n",
    "            \n",
    "            # Skip if no speech found\n",
    "            if not speech_timestamps:\n",
    "                print(f\"No speech found in {base_filename}\")\n",
    "                return\n",
    "\n",
    "            print(f\"Memory Before librosa.load: {memory_usage_mb()}\")\n",
    "            \n",
    "            # Load audio at original sample rate for processing\n",
    "            audio_buffer.seek(0)\n",
    "            y, sr = librosa.load(audio_buffer, sr=None)\n",
    "\n",
    "            print(f\"Memory After librosa.load: {memory_usage_mb()}\")\n",
    "            \n",
    "            # Free memory\n",
    "            del wav\n",
    "            gc.collect()\n",
    "\n",
    "        # Note: audio_buffer automatically closed after the with block\n",
    "        print(f\"Memory After closing audio_buffer: {memory_usage_mb()}\")\n",
    "\n",
    "        print(f\"Memory Before Mask Stuff: {memory_usage_mb()}\")\n",
    "\n",
    "        # Create clean audio by removing voice segments\n",
    "        keep_mask = np.ones(len(y), dtype=bool)\n",
    "        for segment in speech_timestamps:\n",
    "            buffer = 0.5\n",
    "            start_with_buffer = max(0, segment[\"start\"] - buffer)\n",
    "            end_with_buffer = min(len(y) / sr, segment[\"end\"] + buffer)\n",
    "            start_sample = int(start_with_buffer * sr)\n",
    "            end_sample = int(end_with_buffer * sr)\n",
    "            keep_mask[start_sample:end_sample] = False\n",
    "            \n",
    "        # Apply mask to get clean audio\n",
    "        clean_audio = y[keep_mask]\n",
    "        \n",
    "        # Calculate percentage of audio retained\n",
    "        percent_retained = (np.sum(keep_mask) / len(keep_mask)) * 100\n",
    "\n",
    "        print(f\"Memory After Mask Stuff: {memory_usage_mb()}\")\n",
    "        \n",
    "        # Free memory\n",
    "        del y, keep_mask\n",
    "        gc.collect()\n",
    "\n",
    "        print(f\"Memory After deleting mask data: {memory_usage_mb()}\")\n",
    "\n",
    "        print(f\"Memory Before saving audio to s3: {memory_usage_mb()}\")\n",
    "        \n",
    "        # Save clean audio to S3 using context manager\n",
    "        with BytesIO() as clean_audio_buffer:\n",
    "            sf.write(clean_audio_buffer, clean_audio, sr, format='ogg')\n",
    "            clean_audio_buffer.seek(0)\n",
    "            clean_s3_key = f\"{output_prefix}/clean_audio/{parent_dir}/{base_filename}\"\n",
    "            s3_client.upload_fileobj(clean_audio_buffer, output_bucket, clean_s3_key)\n",
    "\n",
    "        print(f\"Memory After saving audio to s3: {memory_usage_mb()}\")\n",
    "        \n",
    "        # Configuration for spectrogram generation\n",
    "        config = {\n",
    "            'sampling_rate': 32000,\n",
    "            'duration': 5,\n",
    "            'fmin': 0,\n",
    "            'fmax': None,\n",
    "            'n_mels': 128,\n",
    "            'res_type': \"kaiser_fast\"\n",
    "        }\n",
    "\n",
    "        print(f\"Memory Before resample if necessary: {memory_usage_mb()}\")\n",
    "        \n",
    "        # Resample if necessary\n",
    "        if sr != config['sampling_rate']:\n",
    "            clean_audio = librosa.resample(\n",
    "                clean_audio, sr, config['sampling_rate'], res_type=config['res_type']\n",
    "            )\n",
    "            sr = config['sampling_rate']\n",
    "\n",
    "        print(f\"Memory After resample if necessary: {memory_usage_mb()}\")\n",
    "        \n",
    "        # Calculate step size (for overlapping windows)\n",
    "        audio_length = config['duration'] * sr\n",
    "        step = int(config['duration'] * 0.666 * sr)\n",
    "\n",
    "        print(f\"Memory Before Split into Chunks: {memory_usage_mb()}\")\n",
    "        \n",
    "        # Split audio into chunks\n",
    "        audio_chunks = [\n",
    "            clean_audio[i:i + audio_length]\n",
    "            for i in range(0, max(1, len(clean_audio) - audio_length + 1), step)\n",
    "        ]\n",
    "        \n",
    "        print(f\"Memory After Split into Chunks: {memory_usage_mb()}\")\n",
    "        \n",
    "        # Ensure last chunk has correct length\n",
    "        if audio_chunks and len(audio_chunks[-1]) < audio_length:\n",
    "            audio_chunks[-1] = crop_or_pad(audio_chunks[-1], audio_length)\n",
    "            \n",
    "        # Free memory\n",
    "        del clean_audio\n",
    "        gc.collect()\n",
    "\n",
    "        print(f\"Memory After delete clean_audio: {memory_usage_mb()}\")\n",
    "\n",
    "        print(f\"Memory Before audio_chunks for loop: {memory_usage_mb()}\")\n",
    "        \n",
    "        # Process each chunk\n",
    "        for i, chunk in enumerate(audio_chunks):\n",
    "            # Create spectrogram\n",
    "            melspec = compute_melspec(\n",
    "                chunk, sr, config['n_mels'], config['fmin'], \n",
    "                config['fmax'] or sr//2\n",
    "            )\n",
    "            image = mono_to_color(melspec)\n",
    "            \n",
    "            # Save as npy file and upload to S3 using context manager\n",
    "            with BytesIO() as npy_buffer:\n",
    "                np.save(npy_buffer, image)\n",
    "                npy_buffer.seek(0)\n",
    "                \n",
    "                # Upload to S3\n",
    "                spec_s3_key = f\"{output_prefix}/audio_specs/{parent_dir}/{base_name}_chunk_{i}.npy\"\n",
    "                s3_client.upload_fileobj(npy_buffer, output_bucket, spec_s3_key)\n",
    "            \n",
    "            # Free memory\n",
    "            print(f\"Memory Before delete stuff in for loop: {memory_usage_mb()}\")\n",
    "            del melspec, image, chunk\n",
    "            gc.collect()\n",
    "            print(f\"Memory After delete stuff in for loop: {memory_usage_mb()}\")\n",
    "\n",
    "        print(f\"Memory After audio_chunks for loop: {memory_usage_mb()}\")\n",
    "        \n",
    "        # Free memory for audio chunks\n",
    "        print(f\"Memory Before delete audio_chunks: {memory_usage_mb()}\")\n",
    "        del audio_chunks\n",
    "        gc.collect()\n",
    "        print(f\"Memory After delete audio_chunks: {memory_usage_mb()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {s3_key}: {e}\")\n",
    "    finally:\n",
    "        # Clean up memory explicitly\n",
    "        print(f\"Memory Before final garbage collection: {memory_usage_mb()}\")\n",
    "        gc.collect()\n",
    "        print(f\"Memory After final garbage collection: {memory_usage_mb()}\")\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "\n",
    "    \n",
    "def main():\n",
    "    # List files from S3\n",
    "    s3_files = list_s3_files(input_bucket, 'train_audio/')\n",
    "    files = sorted([f for f in s3_files if f.endswith('.ogg')])\n",
    "    \n",
    "    # Process files one by one\n",
    "    count = 0\n",
    "    for s3_key in files:\n",
    "        count += 1\n",
    "        print(f\"Processing file {count}/{len(files)}\")\n",
    "        if count > TEST_COUNT_LIMIT:\n",
    "            break\n",
    "            \n",
    "        process_single_file(s3_key)\n",
    "        \n",
    "        # Explicitly clean up memory after each file\n",
    "        gc.collect()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83179fa4-fd21-416d-a1eb-54699bebf086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATES NEW PROCESS EACH TIME AND WORKS (I THINK, NEED TO TEST IT AGAIN)\n",
    "\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "import gc\n",
    "import multiprocessing\n",
    "import psutil\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "def memory_usage_mb():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_bytes = process.memory_info().rss\n",
    "    return f\"{mem_bytes / (1024 * 1024)} mb\"\n",
    "\n",
    "def process_single_file_wrapper(s3_key):\n",
    "    \"\"\"\n",
    "    Wrapper function that spawns a completely new process for each file.\n",
    "    This ensures complete memory cleanup after each file.\n",
    "    \"\"\"\n",
    "    # Create and start a new process for this specific file\n",
    "    p = multiprocessing.Process(target=process_single_file, args=(s3_key,))\n",
    "    p.start()\n",
    "    p.join()\n",
    "    \n",
    "    # Check if process exited normally\n",
    "    if p.exitcode != 0:\n",
    "        print(f\"Warning: Process for {s3_key} exited with code {p.exitcode}\")\n",
    "    \n",
    "    \n",
    "\n",
    "def process_single_file(s3_key, max_size_mb=1.2):\n",
    "    \"\"\"Function to process a single audio file\"\"\"\n",
    "    \n",
    "    # This function now should run in its own isolated process\n",
    "    print(f\"Memory at start: {memory_usage_mb()}\")\n",
    "    \n",
    "    # Initialize resources needed for this process\n",
    "    s3_client = boto3.client('s3')\n",
    "    input_bucket = 'cs401finalpipelineinput'\n",
    "    output_bucket = 'cs401finalpipelineprocessingdata'\n",
    "    output_prefix = 'data'\n",
    "    \n",
    "    try:\n",
    "        # Initialize VAD model - keep this inside the try block to ensure cleanup\n",
    "        torch.set_num_threads(1)\n",
    "        model, (get_speech_timestamps, _, read_audio, _, _) = torch.hub.load(\n",
    "            repo_or_dir=\"snakers4/silero-vad\", model=\"silero_vad\"\n",
    "        )\n",
    "        \n",
    "        # Extract class from directory structure\n",
    "        path_parts = s3_key.split('/')\n",
    "        parent_dir = path_parts[-2]  # Class name\n",
    "        base_filename = path_parts[-1]  # Filename\n",
    "        base_name = base_filename.split('.')[0] if '.' in base_filename else base_filename\n",
    "\n",
    "        print(f\"Process {os.getpid()} - Processing {base_filename}\")\n",
    "        \n",
    "        # Download audio file to memory\n",
    "        with BytesIO() as audio_buffer:\n",
    "            s3_client.download_fileobj(input_bucket, s3_key, audio_buffer)\n",
    "            audio_buffer.seek(0)\n",
    "            \n",
    "            # Check file size\n",
    "            file_size_mb = len(audio_buffer.getvalue()) / (1024 * 1024)\n",
    "            if file_size_mb > max_size_mb:\n",
    "                print(f\"Skipping {base_filename}: {file_size_mb:.1f}MB exceeds {max_size_mb}MB limit\")\n",
    "                return\n",
    "            \n",
    "            # Use BytesIO for VAD model\n",
    "            audio_buffer.seek(0)\n",
    "            wav = read_audio(audio_buffer)\n",
    "            \n",
    "            # Get speech timestamps\n",
    "            speech_timestamps = get_speech_timestamps(\n",
    "                wav, model, return_seconds=True, threshold=0.4\n",
    "            )\n",
    "            \n",
    "            # Skip if no speech found\n",
    "            if not speech_timestamps:\n",
    "                print(f\"No speech found in {base_filename}\")\n",
    "                return\n",
    "            \n",
    "            # Load audio at original sample rate for processing\n",
    "            audio_buffer.seek(0)\n",
    "            y, sr = librosa.load(audio_buffer, sr=None)\n",
    "            \n",
    "            # Free memory\n",
    "            del wav\n",
    "            gc.collect()\n",
    "\n",
    "        # Create clean audio by removing voice segments\n",
    "        keep_mask = np.ones(len(y), dtype=bool)\n",
    "        for segment in speech_timestamps:\n",
    "            buffer = 0.5\n",
    "            start_with_buffer = max(0, segment[\"start\"] - buffer)\n",
    "            end_with_buffer = min(len(y) / sr, segment[\"end\"] + buffer)\n",
    "            start_sample = int(start_with_buffer * sr)\n",
    "            end_sample = int(end_with_buffer * sr)\n",
    "            keep_mask[start_sample:end_sample] = False\n",
    "            \n",
    "        # Apply mask to get clean audio\n",
    "        clean_audio = y[keep_mask]\n",
    "        \n",
    "        # Calculate percentage of audio retained\n",
    "        percent_retained = (np.sum(keep_mask) / len(keep_mask)) * 100\n",
    "        \n",
    "        # Free memory\n",
    "        del y, keep_mask, speech_timestamps\n",
    "        gc.collect()\n",
    "\n",
    "        # Save clean audio to S3\n",
    "        with BytesIO() as clean_audio_buffer:\n",
    "            sf.write(clean_audio_buffer, clean_audio, sr, format='ogg')\n",
    "            clean_audio_buffer.seek(0)\n",
    "            clean_s3_key = f\"{output_prefix}/clean_audio/{parent_dir}/{base_filename}\"\n",
    "            s3_client.upload_fileobj(clean_audio_buffer, output_bucket, clean_s3_key)\n",
    "\n",
    "        # Configuration for spectrogram generation\n",
    "        config = {\n",
    "            'sampling_rate': 32000,\n",
    "            'duration': 5,\n",
    "            'fmin': 0,\n",
    "            'fmax': None,\n",
    "            'n_mels': 128,\n",
    "            'res_type': \"kaiser_fast\"\n",
    "        }\n",
    "        \n",
    "        # Resample if necessary\n",
    "        if sr != config['sampling_rate']:\n",
    "            clean_audio = librosa.resample(\n",
    "                clean_audio, sr, config['sampling_rate'], res_type=config['res_type']\n",
    "            )\n",
    "            sr = config['sampling_rate']\n",
    "        \n",
    "        # Calculate step size (for overlapping windows)\n",
    "        audio_length = config['duration'] * sr\n",
    "        step = int(config['duration'] * 0.666 * sr)\n",
    "        \n",
    "        # Split audio into chunks\n",
    "        audio_chunks = [\n",
    "            clean_audio[i:i + audio_length]\n",
    "            for i in range(0, max(1, len(clean_audio) - audio_length + 1), step)\n",
    "        ]\n",
    "        \n",
    "        # Ensure last chunk has correct length\n",
    "        if audio_chunks and len(audio_chunks[-1]) < audio_length:\n",
    "            audio_chunks[-1] = crop_or_pad(audio_chunks[-1], audio_length)\n",
    "            \n",
    "        # Free memory\n",
    "        del clean_audio\n",
    "        gc.collect()\n",
    "\n",
    "        # Process each chunk\n",
    "        for i, chunk in enumerate(audio_chunks):\n",
    "            # Create spectrogram\n",
    "            melspec = compute_melspec(\n",
    "                chunk, sr, config['n_mels'], config['fmin'], \n",
    "                config['fmax'] or sr//2\n",
    "            )\n",
    "            image = mono_to_color(melspec)\n",
    "            \n",
    "            # Save as npy file and upload to S3\n",
    "            with BytesIO() as npy_buffer:\n",
    "                np.save(npy_buffer, image)\n",
    "                npy_buffer.seek(0)\n",
    "                \n",
    "                # Upload to S3\n",
    "                spec_s3_key = f\"{output_prefix}/audio_specs/{parent_dir}/{base_name}_chunk_{i}.npy\"\n",
    "                s3_client.upload_fileobj(npy_buffer, output_bucket, spec_s3_key)\n",
    "            \n",
    "            # Free memory\n",
    "            del melspec, image\n",
    "            gc.collect()\n",
    "\n",
    "        # Free memory for audio chunks\n",
    "        del audio_chunks\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"Completed {base_filename}, memory: {memory_usage_mb()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {s3_key}: {e}\")\n",
    "        # In case of error, ensure the process exits with non-zero code\n",
    "        sys.exit(1)\n",
    "    finally:\n",
    "        # Clean up memory explicitly\n",
    "        gc.collect()\n",
    "        \n",
    "        # Clean up PyTorch resources\n",
    "        if 'model' in locals():\n",
    "            del model\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            \n",
    "def list_s3_files(bucket, prefix):\n",
    "    \"\"\"List files in an S3 bucket with given prefix\"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n",
    "    \n",
    "    file_list = []\n",
    "    for page in pages:\n",
    "        if \"Contents\" in page:\n",
    "            for obj in page[\"Contents\"]:\n",
    "                file_list.append(obj[\"Key\"])\n",
    "    \n",
    "    return file_list\n",
    "\n",
    "def compute_melspec(audio, sr, n_mels, fmin, fmax):\n",
    "    \"\"\"Compute a mel-spectrogram.\"\"\"\n",
    "    melspec = librosa.feature.melspectrogram(\n",
    "        y=audio,\n",
    "        sr=sr,\n",
    "        n_mels=n_mels,\n",
    "        fmin=fmin,\n",
    "        fmax=fmax,\n",
    "    )\n",
    "\n",
    "    # Convert to log scale (dB)\n",
    "    melspec = librosa.power_to_db(melspec)\n",
    "    return melspec\n",
    "\n",
    "def mono_to_color(X, eps=1e-6, mean=None, std=None):\n",
    "    \"\"\"Convert mono audio to color image format\"\"\"\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    X = (X - mean) / (std + eps)\n",
    "\n",
    "    # Normalize to [0, 255]\n",
    "    _min, _max = X.min(), X.max()\n",
    "    if (_max - _min) > eps:\n",
    "        V = np.clip(X, _min, _max)\n",
    "        V = 255 * (V - _min) / (_max - _min)\n",
    "    else:\n",
    "        V = np.zeros_like(X)\n",
    "\n",
    "    # Convert to uint8\n",
    "    V = V.astype(np.uint8)\n",
    "\n",
    "    # Create RGB channels (stack the same array 3 times)\n",
    "    return np.stack([V, V, V], axis=2)\n",
    "\n",
    "def crop_or_pad(audio, length):\n",
    "    \"\"\"Crop or pad an audio sample to a fixed length.\"\"\"\n",
    "    if len(audio) < length:\n",
    "        # Pad with zeros\n",
    "        audio = np.pad(audio, (0, length - len(audio)))\n",
    "    else:\n",
    "        # Crop to length\n",
    "        audio = audio[:length]\n",
    "    return audio\n",
    "\n",
    "def main():\n",
    "    # Constants\n",
    "    input_bucket = 'cs401finalpipelineinput'\n",
    "    \n",
    "    TEST_COUNT_LIMIT = 500\n",
    "    \n",
    "    # List files from S3\n",
    "    s3_files = list_s3_files(input_bucket, 'train_audio/')\n",
    "    files = sorted([f for f in s3_files if f.endswith('.ogg')])\n",
    "    \n",
    "    if len(files) > TEST_COUNT_LIMIT:\n",
    "        files = files[:TEST_COUNT_LIMIT]\n",
    "    \n",
    "    print(f\"Processing {len(files)} files with separate processes\")\n",
    "    \n",
    "    # Process each file in its own process\n",
    "    for i, s3_key in enumerate(files):\n",
    "        print(f\"Starting file {i+1}/{len(files)}: {s3_key.split('/')[-1]}\")\n",
    "        process_single_file_wrapper(s3_key)\n",
    "    \n",
    "    print(\"All processing complete\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"here\")\n",
    "    multiprocessing.freeze_support()\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d60cd9e-cf59-4472-9d5c-9f7669293ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9f4057-3776-4913-b9e3-3c8a2185e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27822cd-5405-4291-aba0-7d0b38b13463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13257d35-304b-4328-8376-47bbfbdf24ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb464a-5692-4466-ad70-2eecce71ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some usless experimentation pipeline stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb8898d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IMPORTS\n",
    "\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString, ParameterBoolean\n",
    "\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a8afaad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CONSTANTS\n",
    "\n",
    "pipeline_name = \"cs401finalpipeline\"\n",
    "\n",
    "write_bucket = \"cs401finalpipelineprocessingdata\"\n",
    "\n",
    "instance_type = \"ml.t3.medium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "167a2b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. SAGEMAKER SESSION SETUP\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "region = sess.boto_region_name\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "sm_runtime_client = boto3.client(\"sagemaker-runtime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd71790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing local_preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile local_preprocessing.py\n",
    "\n",
    "# import argparse\n",
    "# import logging\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\"--message\", type=str, default=\"N/A\")\n",
    "#     args, _ = parser.parse_known_args()\n",
    "#     logger.info(\"Received arguments {}\".format(args))\n",
    "#     logger.info(f\"Message: {args.message}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a8a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile local_requirements.txt\n",
    "\n",
    "librosa>=0.9.2\n",
    "soundfile>=0.10.0\n",
    "pandas>=1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c835eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file(\n",
    "    Filename=\"local_preprocessing.py\", Bucket=write_bucket, Key=\"scripts/preprocessing/preprocessing.py\"\n",
    ")\n",
    "\n",
    "s3_client.upload_file(\n",
    "    Filename=\"local_requirements.txt\", Bucket=write_bucket, Key=\"scripts/preprocessing/requirements.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "caf27b12",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PyTorchProcessor.__init__() got an unexpected keyword argument 'requirements'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 4. DEFINE DATA PROCESSING ACTUAL STEP\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pytorch_processor \u001b[38;5;241m=\u001b[39m \u001b[43mPyTorchProcessor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframework_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1.12.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msagemaker_role\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstance_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstance_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_job_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpipeline_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-preprocessing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpy_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpy38\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibrosa>=0.9.2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msoundfile>=0.10.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpandas>=1.3.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Define pipeline processing step\u001b[39;00m\n\u001b[1;32m     13\u001b[0m preprocess_step \u001b[38;5;241m=\u001b[39m ProcessingStep(\n\u001b[1;32m     14\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreProcessing\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     processor\u001b[38;5;241m=\u001b[39mpytorch_processor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwrite_bucket\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/scripts/preprocessing/preprocessing.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: PyTorchProcessor.__init__() got an unexpected keyword argument 'requirements'"
     ]
    }
   ],
   "source": [
    "# 4. DEFINE DATA PROCESSING ACTUAL STEP\n",
    "pytorch_processor = PyTorchProcessor(\n",
    "    framework_version=\"1.12.0\",\n",
    "    role=sagemaker_role,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    base_job_name=f\"{pipeline_name}-preprocessing\",\n",
    "    py_version=\"py38\",\n",
    "    source_dir=[\"librosa>=0.9.2\", \"soundfile>=0.10.0\", \"pandas>=1.3.0\"]\n",
    ")\n",
    "\n",
    "# Define pipeline processing step\n",
    "preprocess_step = ProcessingStep(\n",
    "    name=\"PreProcessing\",\n",
    "    processor=pytorch_processor,\n",
    "    inputs=[],\n",
    "    outputs=[],\n",
    "    job_arguments=[\n",
    "        \"--message\", \"Hello World\"\n",
    "    ],\n",
    "    code=f\"s3://{write_bucket}/scripts/preprocessing/preprocessing.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a4eef9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36m[04/17/25 06:56:53]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;33mWARNING \u001b[0m Popping out \u001b[32m'ProcessingJobName'\u001b[0m    \u001b]8;id=83418;file:///opt/conda/lib/python3.12/site-packages/sagemaker/workflow/utilities.py\u001b\\\u001b[2mutilities.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=65179;file:///opt/conda/lib/python3.12/site-packages/sagemaker/workflow/utilities.py#465\u001b\\\u001b[2m465\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         from the pipeline definition by    \u001b[2m                \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         default since it will be           \u001b[2m                \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         overridden at pipeline execution   \u001b[2m                \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         time. Please utilize the           \u001b[2m                \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         PipelineDefinitionConfig to        \u001b[2m                \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         persist this field in the pipeline \u001b[2m                \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         definition if desired.             \u001b[2m                \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;33mWARNING \u001b[0m Popping out \u001b[32m'ProcessingJobName'\u001b[0m    \u001b]8;id=72073;file:///opt/conda/lib/python3.12/site-packages/sagemaker/workflow/utilities.py\u001b\\\u001b[2mutilities.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=435389;file:///opt/conda/lib/python3.12/site-packages/sagemaker/workflow/utilities.py#465\u001b\\\u001b[2m465\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         from the pipeline definition by    \u001b[2m                \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         default since it will be           \u001b[2m                \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         overridden at pipeline execution   \u001b[2m                \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         time. Please utilize the           \u001b[2m                \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         PipelineDefinitionConfig to        \u001b[2m                \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         persist this field in the pipeline \u001b[2m                \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         definition if desired.             \u001b[2m                \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:084375543672:pipeline/cs401finalpipeline',\n",
       " 'ResponseMetadata': {'RequestId': '9623aa6a-ea51-4475-bc04-839953bf5910',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '9623aa6a-ea51-4475-bc04-839953bf5910',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '86',\n",
       "   'date': 'Thu, 17 Apr 2025 06:56:54 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. CREATE PIPELINE\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[],\n",
    "    steps=[\n",
    "        preprocess_step,\n",
    "    ],\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "# Create a new or update existing Pipeline\n",
    "pipeline.upsert(role_arn=sagemaker_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "08150882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_PipelineExecution(arn='arn:aws:sagemaker:us-east-1:084375543672:pipeline/cs401finalpipeline/execution/pzsbk1atso3g', sagemaker_session=<sagemaker.session.Session object at 0x7fd4a16cb740>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. RUN PIPELINE\n",
    "\n",
    "pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c107a17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
